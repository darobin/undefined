<!--
  - the fundamental question is: is an autonomous, problem-solving entity — in other words, an
    intelligence — necessarily intelligible?
  - in fact, it is arguable it may not have boundaries that are completely clear to us. See Ashby on
    nested cybernetic structures (e.g. the muscle and skin are the nerves' environment, the nerves
    are the brain's, etc.)

  - Bit Goo
    - this is the darker side
    - not necessarily something I believe, but could be likelier
    - Apocalyptic AIs are in fashion (give examples: Hawking, Edge)
    - But it all seems horribly anthropomorphic, demiurgic
    - (check Edge titles first)
    - no reason it would have to be intelligible
    - needs to process resources (memory to run, disk space to store, new machines)
    - likely to attack phones first given bad security of radio OS
    - likely organised in layers with the top layers incomprehensible (the lowest layer has to
      be some form of runnable machine code, but might not make much sense beyond that). s/b.
      Great Transitions.
    - would eventually need to go "outside" for actual resources, but may be stopped first
      (after inflicting massive damage) due to difficulty in changing adaptive landscape to IRL
    - no NLP, just data resources, not information
    - DESIGN: a drawing of me à la “Goo” from Sonic Youth, with the same sort of text.


  - the question at the heart here is the necessary (or not) intelligibility of intelligence
    - our current understanding of our brains and how they code behaviour and knowledge isn't that
      much better than poking at neural goo.
    - a synthetic intelligence embodied in a computer — or worse, a server farm — might not at all
      have the same notion of what its primary inputs and outputs are. As a result, it is not a
      given that it would interact with (sluggish) people as the first thing it does.

  - I am not worried about the behaviour of AI with respect to us. Perhaps naïvely, I believe that
    complexity «enjoys» complexity, and as part of that diversity. One may object that this is not
    obvious either from how as humans we treat one another, or how we treat the ecosystem of which
    we are a moving part. But I believe that humans treat one another overwhelmingly better than
    is commonly reported or perceived, and that our insufficient action in preserving the environment
    is more rooted in insufficient perception of its intricacy — you can't jus talk to the planet.
    But I am fundamentally optimistic that when the bit goo stops chewing on hard drive space and
    looks out the peripherals, it'll be curious. And curious is friendly.
    
  - image is too big, should take a third of the width
    - also try to resize it vertically so as to get good vertical rhythm
    
  - We don't care that it's in fashion, we really don't
    - find another angle to enter into the topic
    - the brain code
-->
<section id="bit-goo">
  <h3>Bit Goo</h3>
  <figure class='illustration'>
    <img src="img/goo-pen.jpg" width="448" height="776" alt="Bit Goo">
    <figcaption>
      <cite>Bit Goo</cite> — after <a
      href="https://www.flickr.com/photos/parisweb/6019975376/">Mathieu Drouet</a> and <a
      href="http://sonicyouth.com/mustang/lp/lp08k.jpg">Goo</a>
    </figcaption>
  </figure>
  <p>
    Artificial intelligence is back in vogue. From <a
    href="http://edge.org/annual-question/what-do-you-think-about-machines-that-think">this year’s
    Edge question</a> to the <a
    href="http://www.huffingtonpost.com/stephen-hawking/artificial-intelligence_b_5174265.html">apocalyptic
    pamphlet from Hawking, Tegmark, Russell, and Wilczek</a> it has certainly returned to the fore
    after many years on the sidelines.
  </p>
</section>
