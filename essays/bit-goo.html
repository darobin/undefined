<!--
  - the fundamental question is: is an autonomous, problem-solving entity — in other words, an
    intelligence — necessarily intelligible?
  - in fact, it is arguable it may not have boundaries that are completely clear to us. See Ashby on
    nested cybernetic structures (e.g. the muscle and skin are the nerves' environment, the nerves
    are the brain's, etc.)

  - Bit Goo
    - this is the darker side
    - not necessarily something I believe, but could be likelier
    - Apocalyptic AIs are in fashion (give examples: Hawking, Edge)
    - But it all seems horribly anthropomorphic, demiurgic
    - (check Edge titles first)
    - no reason it would have to be intelligible
    - needs to process resources (memory to run, disk space to store, new machines)
    - likely to attack phones first given bad security of radio OS
    - likely organised in layers with the top layers incomprehensible (the lowest layer has to
      be some form of runnable machine code, but might not make much sense beyond that). s/b.
      Great Transitions.
    - would eventually need to go "outside" for actual resources, but may be stopped first
      (after inflicting massive damage) due to difficulty in changing adaptive landscape to IRL
    - no NLP, just data resources, not information
    - DESIGN: a drawing of me à la “Goo” from Sonic Youth, with the same sort of text.

-->
<section id="bit-goo">
  <h3>Bit Goo</h3>
  <p>
    Artificial intelligence is back in vogue. From <a
    href="http://edge.org/annual-question/what-do-you-think-about-machines-that-think">this year’s
    Edge question</a> to the <a
    href="http://www.huffingtonpost.com/stephen-hawking/artificial-intelligence_b_5174265.html">apocalyptic
    pamphlet from Hawking, Tegmark, Russell, and Wilczek</a> it has certainly returned to the fore
    after many years on the sidelines.
  </p>
</section>
