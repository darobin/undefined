<!--
  - the fundamental question is: is an autonomous, problem-solving entity — in other words, an
    intelligence — necessarily intelligible?
  - in fact, it is arguable it may not have boundaries that are completely clear to us. See Ashby on
    nested cybernetic structures (e.g. the muscle and skin are the nerves' environment, the nerves
    are the brain's, etc.)

  - Bit Goo
    - this is the darker side
    - not necessarily something I believe, but could be likelier
    - Apocalyptic AIs are in fashion (give examples: Hawking, Edge)
    - But it all seems horribly anthropomorphic, demiurgic
    - (check Edge titles first)
    - no reason it would have to be intelligible
    - needs to process resources (memory to run, disk space to store, new machines)
    - likely to attack phones first given bad security of radio OS
    - likely organised in layers with the top layers incomprehensible (the lowest layer has to
      be some form of runnable machine code, but might not make much sense beyond that). s/b.
      Great Transitions.
    - would eventually need to go "outside" for actual resources, but may be stopped first
      (after inflicting massive damage) due to difficulty in changing adaptive landscape to IRL
    - no NLP, just data resources, not information
    - DESIGN: a drawing of me à la “Goo” from Sonic Youth, with the same sort of text.


  - the question at the heart here is the necessary (or not) intelligibility of intelligence
    - our current understanding of our brains and how they code behaviour and knowledge isn't that
      much better than poking at neural goo.
    - a synthetic intelligence embodied in a computer — or worse, a server farm — might not at all
      have the same notion of what its primary inputs and outputs are. As a result, it is not a
      given that it would interact with (sluggish) people as the first thing it does.

  - I am not worried about the behaviour of AI with respect to us. Perhaps naïvely, I believe that
    complexity «enjoys» complexity, and as part of that diversity. One may object that this is not
    obvious either from how as humans we treat one another, or how we treat the ecosystem of which
    we are a moving part. But I believe that humans treat one another overwhelmingly better than
    is commonly reported or perceived, and that our insufficient action in preserving the environment
    is more rooted in insufficient perception of its intricacy — you can't jus talk to the planet.
    But I am fundamentally optimistic that when the bit goo stops chewing on hard drive space and
    looks out the peripherals, it'll be curious. And curious is friendly.
    
  - also try to resize image vertically so as to get good vertical rhythm
    
  - We don't care that it's in fashion, we really don't
    - find another angle to enter into the topic
    - the brain code
  
  - We still don't have an understanding of the Brain’s code; our presumption that AI will be
    understandable is therefore rooted in the hope that when it emerges, it will prefer to interact
    through the peripherals that give it a direct interface to us rather than through other parts of
    its environment. How can we tell that, to an entity born into a computer, the hard drive,
    volatile memory, or network interface won't be far more attractive than a webcam or keyboard
    input?
  - We can't. See Ashby when he says that the environment of the nerves is the muscle, skin, and
    bones; the environment for the brain is the nerves; and so on.
  - if the Brain Code looks like Goo, then it is extremely likely that AI, when sprouting into
    existence, *even if it is not modelled after biological systems*, will look like Bit Goo.
  - How do we go from there? How do we capture the intelligibility of intelligence?
-->
<section id="bit-goo">
  <h3>Bit Goo</h3>

  <figure class='illustration'>
    <img src="img/goo-pen.jpg" width="300" height="533" alt="Bit Goo">
    <figcaption>
      <cite>Bit Goo</cite> — after <a
      href="https://www.flickr.com/photos/parisweb/6019975376/">Mathieu Drouet</a> and <a
      href="http://sonicyouth.com/mustang/lp/lp08k.jpg">Goo</a>
    </figcaption>
  </figure>

  <p>
    Artificial intelligence is back in vogue. From <a
    href="http://edge.org/annual-question/what-do-you-think-about-machines-that-think">this year’s
    Edge question</a> to the <a
    href="http://www.huffingtonpost.com/stephen-hawking/artificial-intelligence_b_5174265.html">apocalyptic
    pamphlet from Hawking, Tegmark, Russell, and Wilczek</a> it has certainly returned to the fore
    after many years on the sidelines.
  </p>
</section>
