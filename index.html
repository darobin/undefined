<!DOCTYPE html>
<html lang='en'>
  <head>
    <meta charset='utf-8'>
    <meta name='viewport' content='width=device-width'>
    <link rel='icon' href='/img/icon.png'>
    <title>Undefined Discipline — Robin Berjon</title>
    <link rel='stylesheet' href='/css/a305b07625116a0b34b302d3390c7bbe.min.css'>
    <!--
      «Não sou nada.
       Nunca serei nada.
       Não posso querer ser nada.
       À parte isso, tenho em mim todos os sonhos do mundo.»
       — Tabacaria, Álvaro de Campos (Fernando Pessoa)
    -->
  </head>
  <body>
    <main>
      <header>
        <h1><span class='title'>Undefined Discipline</span> <span class='name'>Robin Berjon</span></h1>
      </header>

      
<!--
  - "tinkering philosopher"
  - "rigorous curiosity and weather-hardened practice"
  - Adversarial design?
  - "Most CVs are angled to pitch a specific aspect or set thereof that best matches the job. They
    are projections to lower dimensions. This page is an attempt to present a _unified self_ over
    what is really a bunch of wild but collegial personalities."
  - good writing (with links?)
  - standards all over the place (do insist on multidisciplinarity)
  - has to be the medialab because that job listing is the one I've been waiting for since high
    school (went into philosophy because I thought it would be the only place that could touch on
    everything — but it was a disappointment) and I don't think
  - fearless: I don't mind being wrong, I've made a career out of picking jobs I was unqualified
    for before starting on them, I don't mind going on stage topless...
      - show several of the less sane pictures
  - being usefully wrong, even if it's only making personal progress
  - impostor's syndrome as a way of life
  - When W3C first offered me to lead a working group, they initially forgot to remove internal
    notes about «that troublesome Robin».
  
  - «The Media Lab is a cross-disciplinary research organization focusing on the invention of new
    media technologies that radically improve the ways people live, learn, work, and play.»
    - that sounds a lot like W3C, or what it would like to be
    - I am intimately familiar with the sentiment behind that vision but am spoiling for the
      occasion to be far more radical about it.
      
  FOCUS:
    - very quick self-intro
    - the two first quotes must get in there
    - then it's all about WHY THE MEDIA LAB
-->
<section id="intro">
  <p>
    The <a href="http://www.media.mit.edu/about/faculty-search">faculty search posting</a> requested
    someone «<span class="q">deeply versed in a minimum of two fields</span> ». In my case, it is
    very precisely two: «<strong>Web technology</strong>» taken in a broad sense that reaches across numerous
    domains, and «<strong>Miscellaneous</strong>». I am particularly good at the latter.
  </p>
  <p>
    The reason I must apply for this position is simple: while my work on the Web already
    covers much ground (from graphics to wire formats, from prototyping to negotiation,
    with technology as a social science), my interests are broader. As a result, many ideas that
    occur to me have to lay unbaked in notebooks, many areas of interest have to lay fallow and
    make do with what time I can marshall after work and family have been accounted for.
  </p>
  <p>
    While I do make slow progress on these topics and have seen some limited successes, it is
    frustrating. I spoil to be a tinkering philosopher by day, not just after mild-mannered citizens
    have gone to bed.
  </p>
  <p>
    I include a short selection of ideas and an overview of my reading pile in the hope to entice
    you to join my curiosity.
  </p>
  <!--
    XXX
      - this is a start, but it's too passive and whimpering
      - more active: change the world, have an impact, do things
      - don't self justify, have done things, want to do more in exploring new areas
      - be troublesome
  -->
</section>


      <nav>
        <ul>
          <li><a href="#intro">Intro</a></li>
          <li><a href="#ideas">Ideas</a></li>
          <li><a href="#cv">Résumé</a></li>
          <li><a href="#public">Public</a></li>
          <li><a href="#books">Reading</a></li>
          <li><a href="#contact">Contact</a></li>
        </ul>
      </nav>


      
<!--
  XXX
  - needs intro blurb
-->
<section id="ideas">
  <h2>Ideas</h2>
  
  
<section id="participation">
  <h3>Participation Architecture</h3>

  <figure class="illustration">
    <img src="img/party.jpg" width="300" height="648" alt="The Pig and Sheep Party">
    <figcaption>
      <cite>It’s a Party!</cite> <!-- — Irène Berthezène -->
    </figcaption>
  </figure>

  <p>
    The question of how to organise groups into a harmonious, cooperative ensemble is not new. But
    whereas frameworks for instance described in
    <a href="http://en.wikipedia.org/wiki/Politics_%28Aristotle%29">Aristotle’s
    <cite>Politics</cite></a> or experimented with in
    <a href="http://en.wikipedia.org/wiki/Phalanst%C3%A8re">Fourier’s Phalanstère</a> tended towards
    requiring the full commitment of one’s energies, the appearance of the Web has made tinkering
    with collective organisation much easier.
  </p>
  <p>
    And tinker we have. There are not enough clichés in the world to convey the impact that the Web
    has had on social experimentation. Yet, for the most part, we have done so naïvely. In saying
    this I point no fingers. In 2010 I published a short booklet called <a
    href="http://www.fondapol.org/etude/berjon-internet-politique-coproduction-citoyenne/"><cite>Internet,
    politique et coproduction citoyenne</cite></a> («Internet, Politics, and Citizen Coproduction»,
    later re-edited as part of <a
    href="http://www.puf.com/Autres_Collections:Innovation_politique_2012"><cite>Innovation
    Politique 2012</cite></a> with the <a href="http://www.puf.com/Accueil">Presses Universitaires
    de France</a>) which described issues with how French political parties made use of the Web and
    proposed a model for citizens to take part in legislative production derived from the manner in
    which the open standards of the Web are produced. It is safe to say that it was just as naïve as
    anyone else’s.
  </p>
  <p>
    For all that we may have been retrospectively innocent, I see no reason to cast off optimism.
    Research into social networking has much improved. Reading <a
    href="http://en.wikipedia.org/wiki/Milgram_experiment">Milgram’s experiment</a> from fifty years
    ago and contrasting it with the research being carried out today based on massive amounts of
    human networking information is heartening. Google’s success in search can, perhaps with a pinch
    of salt, be seen as little more than applied sociology. Our understanding of the structure of
    society and of the flow of information through it is blossoming; and there is much more to be
    built from it.
  </p>
  <p>
    Yet the core question remains: <em>How do we design for participation?</em>
  </p>
  <p>
    It is time to turn research into action and to find out how we can convert analysis into actual
    design decisions for collective services. For instance, if it were to surface that successful
    collective services are systematically structured around a <a
    href="http://en.wikipedia.org/wiki/Small-world_network">Small-World network</a>, the question
    would become: how do we design interactions and structure the flow of information such that a
    Small-World network would naturally emerge in the service? And mutatis mutandis for any other
    such finding.
  </p>
  <p>
    This is no easy task. Facebook for instance is clearly floundering in its attempt to make its
    timeline — an unstructured all-to-one feature — usable despite the actual connections between
    its users having a genuine social topology. Knowing what works does not necessarily tell us how
    to build it.
  </p>
  <p>
    A programme to explore this space need not start by boiling the ocean. On the contrary, creating
    small, targeted endeavours (on or off the Web) to experiment with modest but world-improving
    goals should progressively help inform the emerging craft of participation architecture. <span
    class="end">•</span>
  </p>
</section>

  <section id="mathesis">
  <h3>Why There Must Be Something</h3>
  
  

  <!--
    - There is a fine line between ambitious theorising and crackpot ideas. The ambition I have in
      approaching this topic is certainly well within the danger zone.
    - My planned approach is to start small and try to discover small improvements. The goal should
      remain bold, but progress should be made in steps.
    - The smallest starting point is to start reproducing a number of code experiments in which order
      appears out of randomness (Bak's avalanches or critical brain, Kauffman's NK models and random
      Boolean networks come to mind, s/b models) in a context that makes them hackable (and with simple
      explanations). The idea is to enable simple tinkering based on minimal expertise. This could
      enable not only better intuitions but also contribute to greater literacy on the topic.

    - HACK: Bak's avalanches here, as a demo? If so, make sure to put it close to the start of the
      article, and the article at the top of the essays

    - There have been many experiments showing that interesting order emerges from simple, random
      systems. In at least some cases, this order appears to be a major force in shaping what systems
      can arise and evolve naturally — including, according to SK in The Origins of Order, imposing
      limits on natural selection's power to shape beings.
    - If such emergent order is a fundamental force in the universe, there is no reason to believe that
      it may not act equally in many disparate parts of reality, in physics just as much as in biology;
      in fast mental processes just as much as in slow evolutionary ones.

    - detail the full research programme
    - still in very early stages since it is put together on a very small amount of time
    - Descartes: "realised that it was necessary, once in a lifetime [semel in vita], to demolish
      everything completely and start again right from the foundations if I wanted to establish
      anything at all in the sciences that was stable and likely to last." (Mediations)

  -->

  <span class="end">•</span>

</section>

  
<section id="moocs">
  <h3>MOOCs off the Cowpath</h3>

  <p>
    MOOCs have done more than any other modern system to propagate, entrench, and magnify the
    mistakes, tropes, and blinds spots of academic teaching.
  </p>
  <p>
    While the broad and largely free availability of knowledge is undoubtedly progress, MOOCs today
    are little more than videoed courses with multiple-choice questions. If we take into account the
    fact that the constraints that produced the traditional course organisation do not necessarily
    apply on the Web, we can open the door to innovation in learning that can not only improve
    learning for all, but more specifically for some who have fared poorly in academic settings.
    There have been some interesting experiments (<a href="https://mooculus.osu.edu/">mooculus</a>
    for instance) but there remains much to be done.
  </p>
  <p>
    To begin with, delivery formats need to be varied. It was once believed that television would
    revolutionise learning by making courses available to all; while this largely failed to become
    a reality MOOCs are nevertheless now using the Web as a more convenient VHS delivery service.
    Text-based courses, where applicable with embedded interactive content, can prove more
    convenient for some topics or for some students. It is much easier to pace one’s reading to
    match one’s understanding. Audiobooks are also a highly popular medium, and they can be listened
    to while carrying out relatively automatic tasks, yet listening to the audio of existing MOOCs
    will often lead to frustration as the lecturer regularly refers to material being presented
    visually. Needless to say, a multi-support approach also leads to better accessibility.
  </p>
  <p>
    The notion that a lecture ought to fit neatly inside of an hour is another constraint that no
    longer applies. While courses developed specifically for MOOCs have generally departed from this
    arrangement, they have yet to take the next logical step. Courses are still designed as
    multiple-week affairs aiming to increase one’s proficiency in a specific discipline. A student
    wishing to learn a single notion will likely have to wade through a lot of material before
    pinpointing it, assuming the course is even continuously available and not restricted to
    time-bound sessions much in the way that 20th century television used to be.
  </p>
  <p>
    We need to enable bite-sized learning. One should be able to find and study a course on just the
    specific topic that one wishes to learn about. If that specific course builds upon other topics
    that one may need to become familiar with first, these can be made available through a
    technology that seems to have yet to revolutionise the MOOC universe: hypertext links. Of
    course, there is no reason why a set of bite-sized lessons could not still be listed as
    a complete, coherent, and long session; it is simply required that they be individually
    discoverable and accessible.
  </p>
  <p>
    In many ways we are missing a manner of Wikipedia for learning. Wikipedia is a great reference
    but anyone who has tried to pick up an advanced topic from it is likely to have noted that it
    can prove lacking in pedagogy.
  </p>
  <p>
    In teaching through a MOOC I saw first-hand how powerful the interactions in the community of
    students were and how much they helped people learn. But they only served those who managed to
    study at the course’s pace, since it was a time-based MOOC those who fell behind often found it
    doubly daunting to have to catch up with the forum discussions in addition to the course
    material itself.
  </p>
  <p>
    More fluid teaching formats would also help foster more helpful communities of learning, which
    could also serve as differentiators between the companies that compete in this space. Students
    could set up pace groups that would allow those who so desire to synchronise the speed at which
    they go through a longer course session. The
    <a href="http://stackoverflow.com/">Stack Overflow</a> family of sites have shown that
    user-curated Q&amp;A can work well.
  </p>
  <p>
    We can really make the world a place of learning; we’ve brought the courses to the Web, now we
    need to bring the Web into the courses. <span class="end">•</span>
  </p>
</section>

  
<section id="bit-goo">
  <h3>Bit Goo</h3>

  <figure class="illustration">
    <img src="img/goo-pen.jpg" width="300" height="533" alt="Bit Goo">
    <figcaption>
      <cite>Bit Goo</cite> — after <a
      href="https://www.flickr.com/photos/parisweb/6019975376/">Mathieu Drouet</a> and <a
      href="http://sonicyouth.com/mustang/lp/lp08k.jpg">Goo</a>
    </figcaption>
  </figure>

  <p>
    We are making progress on cracking the brain’s own internal coding, but for the time being much
    of it is still a hodgepodge of signals. In this light, it may seem somewhat surprising that our
    expectations when things come to artificial intelligence are that it would be more or less
    instantly recognisable through its direct interactions with the channels we have built to
    interface with it. Our presumption that AI will be understandable is therefore rooted in the
    hope that when it emerges, it will prefer to interact through the peripherals that give it a
    direct interface to us rather than through other parts of its environment. How can we tell that,
    to an entity born into a computer, the hard drive, volatile memory, or network interface won’t
    be far more attractive than a webcam or keyboard input?
  </p>
  <p>
    We can’t. In fact, it is arguable that it may not have boundaries that are completely clear to
    us. In the same way that the brain’s immediate environment is the nervous system much more than
    the world external to us, a synthetic intelligence embodied in a computer — or in a server farm
    — might not at all share our notion of what its primary inputs and outputs are. As a result,
    it is not a given that it would be motivated to interact with (sluggish) people as the first
    thing it does.
  </p>
  <p>
    If the brain code looks like neural goo, then it is extremely likely that AI, when sprouting
    into existence, <em>even if it is not biomimetic</em>, will look like <em>bit goo</em>. For all
    we know, as an autonomous entity it could be drawn to expand to use as many computing resources
    as it can, exploiting the many security vulnerabilities present on connected devices, leaving an
    incomprehensible trail being of the digital equivalent of the grey goo found in apocalyptic
    nanotechnology fiction.
  </p>
  <p>
    I do not believe in such a catastrophic outbreak, even if I would not be surprised if the
    initial reach of a synthetic intelligence into the world were to clumsily break a few things.
    Perhaps naïvely, I believe that complexity «enjoys» complexity, and as part of that diversity.
    One may object that this is not obvious either from how as humans we treat one another, or how
    we treat the ecosystem of which we are a moving part. But humans treat each other overwhelmingly
    better than is commonly reported or perceived, and I intuit that our insufficient action in
    preserving the environment is rooted in our insufficient perception of its intricacy: you can’t
    just talk to the planet, its interaction web is a lot to take in. But I am fundamentally
    optimistic that when the bit goo stops chewing on hard drive space and looks out the
    peripherals, it will be curious. And curious is friendly.
  </p>
  <p>
    In the meantime, the question of the necessary intelligibility of intelligence is open. How do
    we even notice that intelligence is happening when it might start happening much before it is
    able to meaningfully interact? I am curious to tinker in what we can extract from the neural
    goo with the hope that some of the mechanisms of its organisation might just be universal enough
    to deduce an intelligence test that could tease out nascent intelligence in bit goo.
    <span class="end">•</span>
  </p>
</section>

  <section id="symbook">
  <h3>The Symbook</h3>

  <p>
    Research as to whether reading on paper or on screens remains so far relatively inconclusive. In
    the absence of clear-cut results, it strikes me as intuitively true nevertheless that both have their
    advantages. Ebooks feature precious capabilities such as obtaining word definitions with a touch
    of one’s finger and extracting highlights and marginalia in electronic form; and they are far
    more convenient than a suitcase half-filled with books. Paper, however, has its topography.
    When digging into a complex text, it is easier to trace one’s steps through reasoning that spans
    several pages. It is easier to flip a few pages to get a sense of whether the author is drawing
    their point to a close with the chapter or still has further arguments to make. Scribbling in
    the margins with a pencil also somehow feels of greater engagement with the author than typing
    in annotations. Such non-textual cues bolster the reading experience and likely help it stick.
  </p>
  <p>
    The idea of the Symbook is that we can get the convenience of ebooks and the physicality of
    paper books all at once.
  </p>
  <p>
    The increased availability of flexible electronics leads to this very simple concept: a book
    made exclusively of sheets of flexible screens. Depending on one’s favoured book heft it can
    come in various sizes and different number of pages.
  </p>
  <p>
    When a book is loaded into the Symbook it is rendered across all the pages. Naturally, books
    are unlikely to make use of exactly the available number of pages but this minor inconvenience
    does not detract much from the improved experience. Shorter books simply stop early (and the
    remaining pages can be made visibly empty, e.g. with a dark side, so as not to lose the sense
    of location), longer books can be split into volumes.
  </p>
  <p>
    Additionally, touch or stylus modalities can support all of the interactions one expects from a
    books, be it dictionary lookup or scribbling.
  </p>
  <p>
    Granted, such a device would as of today be expensive, may appear gratuitous, and would no doubt
    require a substantial battery. But as an archetype I think it worth pondering. Over the past
    decades the digital world has progressively weaned itself from mimicking the analog and has
    developed interfaces all its own that fit our intuitions at times better than analog objects
    ever have. These improvements need not stay confined to our screens, they should flow back into
    the analog until we cease to know the difference. <span class="end">•</span>
  </p>
</section>

  
<section id="boltzmann">
  <h3>Boltzmann Replicators</h3>
  <p>
    In his <cite>Meditations</cite>, Descartes’ «Malin Génie» has him live in a radically
    solipsistic world in which not only do other people not exist but one is nothing other than mind
    tricked into believing it has a body moving about the world.
  </p>
  <p>
    The «Boltzmann Brain» is modern cosmology’s take on this idea, with a cold, uncaring,
    high-entropy universe stepping in as a more contemporary take on the evil demon. It stems from
    Ludwig Boltzmann’s hypothesis that the world in which we live is a (large) random fluctuation
    towards lower entropy leading to spontaneous and extremely improbable order. Assuming a
    distribution of such fluctuations that makes their likelihood inversely proportional to their
    size and complexity, it would seem to be a <em>lot</em> more statistically likely that you, dear
    reader, are nothing more than a self-aware fluctuation operating under the delusion that it is
    living in a genuine universe rather than being an actual being in a fluctuation of universe
    proportions. Put differently, a mind, full of thoughts, memories, and perceptions, is
    (obviously) orders of magnitude simpler than the entirety of the universe — it is, under this
    thought experiment, therefore orders of magnitude more likely to exist on its own.
  </p>
  <p>
    I am not convinced that order is, in fact, improbable. Going over (for instance) Stuart
    Kauffman’s experiments as detailed in <cite>The Origins of Order</cite>, it seems at least
    conceivable that thermodynamics are only telling part of the story. Having said that, with the
    pleasure of staying within the confines of the thought experiment, I wonder if there is not
    possibly a more powerful consequence.
  </p>
  <p>
    A mind is already something inordinately complex for a purely stochastic fluctuation to produce.
    I wonder if, in the amount of time required for a mind to fluctuate into existence, something
    far simpler would not have had a chance to emerge, with far greater impact. A structure the only
    interesting property of which being that it is able to make use of the tiny amount of background
    energy surrounding it to do just one thing: making copies of itself. A <em>replicator</em>.
  </p>
  <p>
    A «Boltzmann Replicator», assuming it is possible, would engender energy gradients. It would
    multiply, mutate, diversify, compete, evolve. After a while, long but much shorter than ergodic
    timescales, a universe might even come out of it. <span class="end">•</span>
  </p>
</section>

  
<section id="web-schema">
  <h3>Web Schema</h3>

  <figure class="illustration">
    <img src="img/moostrich.jpg" width="300" height="533" alt="The Moostrich">
    <figcaption>
      <cite>The Moostrich</cite> (not from the Galápagos)
    </figcaption>
  </figure>

  <p>
    The <a href="http://en.wikipedia.org/wiki/Gal%C3%A1pagos_syndrome">Galápagos syndrome</a>,
    derived from Darwin’s observations of how species had walked down their own evolutionary path in
    the isolated environment of the Galápagos islands, was initially coined to describe the manner
    in which Japanese phones were for over a decade featuring advanced capabilities that were rarely
    spread abroad. It can however be equally well applied in other contexts. The French
    <a href="http://en.wikipedia.org/wiki/Minitel">Minitel</a> is one such example. Semantic Web
    technologies are another, which is a major factor in their currently relatively limited
    deployment.
  </p>
  <p>
    Yet the necessity of a machine-processable Web of data is as real as ever. Open data continues
    to become massively available, but without an increase in widespread ability to process it
    easily its power goes largely untapped. The hugely diverse data sets that are bound to be
    produced by connected objects can only make the issue more pressing. Unused data is but a waste
    of bits, in order to enable a new generation of services on the Web we need to increase
    <em>data mungeability</em>.
  </p>
  <p>
    There have been improvements. JSON-LD has opened a tenuous bridge between Semantic Web
    technologies and run-of-the-mill Web development; ongoing work to turn sturdy old CSV into a
    first-class Web format will help further; and the slow but steady growth of Microdata and RDFa
    embedded in Web documents is slowly granting search engines power beyond text and links
    processing. But most of the benefits are so far being reaped by the large search engines rather
    than by a broader population. The <a href="http://commoncrawl.org/">Common Crawl</a> can help,
    but only so far as data is published on typical Web sites.
  </p>
  <p>
    The causes behind this mismatch are not specific to Semantic Web technologies. As a community we
    need to become much better at <em>transition thinking</em>. It is never enough to just solve a
    problem by inventing technology: one also needs to know how to get people from here to there. In
    other words everyone might want a flying car, but if it requires years of intensive training to
    use it, no matter how great the antigrav engine, no matter how many dream of it, no matter that
    it may be enough to fend off global warming it will still fail. Technology is first and foremost
    a behavioural science.
  </p>
  <p>
    The goal of the <em>Web Schema</em> project is to reboot the Semantic Web by rooting a new batch
    of data technology in the vernacular of everyday Web development. The primary use case is to
    enable developers to start from what they typically already have — a JSON-based API — and allow
    them to enhance it iteratively in a manner that serves their immediate interests in producing
    Web content.
  </p>
  <p>
    A Web Schema models data in a manner that is at the natural intersection between JSON formats
    and HTML forms, with default rules that lend themselves to progressive enhancements (as opposed
    to having to produce a data ontology from scratch). Through this, it enables data validation on
    both the server (for security) and the client (for usability), it makes it possible to generate
    forms, to optimise database storage, and to document Web APIs. These features make Web Schema
    directly useful to developers, and by providing enhanced data descriptions in a manner that is
    built-in rather than bolted-on as with traditional metadata it provides a natural bootstrapping
    step to a Web of much higher quality data for all to use. <span class="end">•</span>
  </p>
</section>

  <section id="wocuments">
  <h3>Self-Editable Documents</h3>

  <p>
    Digital documents today come in either of two kinds. They can be <em>packaged documents</em>, in
    which case they are generally available as files on one’s hard drive, and can be copied and
    emailed around. Each type of packaged document requires a specialised application to view or
    edit them (often the same for both, but not necessarily). It is not uncommon for such
    applications to become bloated with features one does not need and to increase in complexity
    beyond the preferences of most users. A good example is Microsoft Office. Or they can be
    <em>hosted documents</em>, sitting on a third-party’s server. Hosted documents can frequently be
    shown to others who need not run anything other than a Web browser, but their content is in
    someone else’s keep with the obvious implications this has for security, privacy, and
    persistence. One instance of such an approach is Google Docs.
  </p>
  <p>
    We should not have to choose between ease of use and privacy, between universality and data
    ownership.
  </p>
  <p>
    Self-editable documents are documents that contain both their content and the implementation
    that makes it possible to render and edit them. Hosted documents have demonstrated that the Web
    platform is powerful enough for advanced document editing, and SEDs avail themselves of this
    capability. They are simply interactive Web content packaged up in a neat exchangeable file, and
    brought to life by a single runtime for all such documents which is essentially a browser view
    into the package. Carrying around the editing implementation with every document will have only
    a minor impact on size as the brunt of the complexity resides in the Web runtime; most editing
    environments can be supported with a few hundred kilobytes of JavaScript; the simpler ones less
    so.
  </p>
  <p>
    One first value of SEDs is the diversity they enable: no matter how abstruse my choices in
    editing setup, I can still send others the document and they will be able to read it. This has
    an impact on archivability as well since a single format built atop Open Web technologies is
    essentially archivable in perpetuity, with no necessity to find a copy of a discontinued
    editor that only runs on an ancient operating system.
  </p>
  <p>
    This diversity also enables specialisation. Using the same editor for letters and novels,
    reports and speeches, specifications and articles, vector art and holiday cards leads to poor
    user experiences. Thanks to the format’s universality, one can have an very simple editor
    dedicated to letters and another, different one for structured long-form. And there is no need
    to remember which application is used for what type of file: a new document is created simply by
    copying an existing one and replacing the content.
  </p>
  <p>
    In order to foster a thriving ecosystem of SED types, it is possible for the rendering code to
    be runnable by all while the editing code requires the acquisition of a license. This maintains
    the universality of the format while providing economic incentives for the creation of high
    quality self-editable document types.
  </p>
  <p>
    Beyond simple convenience this approach is the only one that comes to mind with the ability to
    break the stranglehold of Microsoft, Adobe, Google, and other such large players over the
    document space. <span class="end">•</span>
  </p>
</section>

  
</section>

      
      
      
      <section id="contact">
  <h3>Contact &amp; Colophon</h3>
  
  

  <a href="http://creativecommons.org/licenses/by/4.0/legalcode">CC-BY</a>
  Robin Berjon
  &lt;<a href="mailto:robin@berjon.com">robin@berjon.com</a>>
  •
  <a href="http://berjon.com/">http://berjon.com/</a>
  •
  <a href="https://twitter.com/robinberjon">@robinberjon</a>
  •
  <a href="https://github.com/darobin/undefined">fork this project</a> (or, you know, just have fun with it)

  <span class="end">•</span>

</section>


    </main>
    <script src='/js/b20b93c653ba4f5d175a4a32d67892ed.min.js'>
  </body>
</html>
